labs(
x = "Left–Right position (RILE, MPDS)",
y = "Climate attention (window tokens / all tokens)",
title = "Quadrant plot: ideology (RILE) × climate attention"
) +
theme_minimal()
#  按党派取均值（每党一个点）
party_mean <- party_election %>%
group_by(partyabbrev, partyname) %>%
summarise(
mean_attention = mean(attention, na.rm = TRUE),
mean_rile      = mean(rile, na.rm = TRUE),
n_elections    = sum(!is.na(attention) & !is.na(rile)),
.groups = "drop"
) %>%
filter(!is.na(mean_attention), !is.na(mean_rile), n_elections > 0)
install.packages("ggrepel")
library(ggrepel)
install.packages("ggrepel")
ggplot(party_mean, aes(x = mean_rile, y = mean_attention, label = partyabbrev)) +
geom_vline(xintercept = 0, linetype = "dashed") +
geom_hline(yintercept = median(party_mean$mean_attention, na.rm = TRUE), linetype = "dashed") +
geom_point(size = 3, alpha = 0.85) +
ggrepel::geom_text_repel(size = 4, max.overlaps = 50) +
labs(
x = "Mean Left–Right position (RILE, MPDS)",
y = "Mean climate attention",
title = "Party means: ideology (RILE) × climate attention"
) +
theme_minimal()
View(uk_qs_501)
View(uk_doc)
# 如果你已经把模型下载到本地，就填本地文件夹；否则用 HF 的 repo id 在线拉取
SENT_LOCAL <- "D:/hf_models/climatebert_sentiment"   # 你可以改成自己的路径；没有就不用建
COMM_LOCAL <- "D:/hf_models/climatebert_commitment"  # 同
CLIM_SENT_MODEL <- if (dir.exists(SENT_LOCAL)) normalizePath(SENT_LOCAL) else "climatebert/distilroberta-base-climate-sentiment"
CLIM_COMM_MODEL <- if (dir.exists(COMM_LOCAL)) normalizePath(COMM_LOCAL) else "climatebert/distilroberta-base-climate-commitment"
## 用 python 端加载两个 pipeline，并定义可从 R 调用的批量预测函数
py_run_string(sprintf("
from transformers import pipeline
import math
SENT_MODEL = r'''%s'''
COMM_MODEL = r'''%s'''
sent_pipe = pipeline('text-classification', model=SENT_MODEL, truncation=True, max_length=256)
comm_pipe = pipeline('text-classification', model=COMM_MODEL, truncation=True, max_length=256)
def _run_pipe(pipe, texts, batch_size=16):
labels, scores = [], []
for i in range(0, len(texts), batch_size):
batch = texts[i:i+batch_size]
preds = pipe(batch, batch_size=batch_size, truncation=True)
for p in preds:
# 有些pipeline会返回 list[list[dict]]；稳妥处理一下
if isinstance(p, list):
p = p[0]
labels.append(p.get('label'))
scores.append(float(p.get('score', math.nan)))
return {'label': labels, 'score': scores}
def climate_sentiment(texts, batch_size=16):
return _run_pipe(sent_pipe, list(texts), batch_size)
def climate_commitment(texts, batch_size=16):
return _run_pipe(comm_pipe, list(texts), batch_size)
def sent_id2label():
return dict(sent_pipe.model.config.id2label)
def comm_id2label():
return dict(comm_pipe.model.config.id2label)
", CLIM_SENT_MODEL, CLIM_COMM_MODEL))
py_run_string("
import torch
print('CUDA available:', torch.cuda.is_available())
if torch.cuda.is_available():
print('GPU:', torch.cuda.get_device_name(0))
")
nvidia-smi
green_text_df <- tibble(
manifesto_id = docnames(toks_green),
green_text = vapply(as.list(toks_green), function(x) paste(x, collapse = " "), character(1))
) %>%
mutate(green_text = stringr::str_squish(green_text))
View(green_text_df)
View(green_text_df)
qs_df <- uk_qs %>%
mutate(
manifesto_id = as.character(manifesto_id),
# MP 的 date 常见是 YYYYMMDD / YYYYMM / YYYY
date_chr = as.character(date),
year = as.integer(stringr::str_sub(date_chr, 1, 4)),
qs_text = stringr::str_squish(as.character(text))
) %>%
filter(!is.na(qs_text), nchar(qs_text) > 0)
View(qs_df)
## （可选但推荐）给每条准句一个长度权重：避免“超短句”对比例影响过大
qs_df <- qs_df %>%
mutate(qs_nwords = stringr::str_count(qs_text, "\\S+") + 0L)
batch_size <- 16  # CPU 建议 8~32 之间试；越大越快但越吃内存
sent_res <- py$climate_sentiment(as.list(qs_df$qs_text), batch_size = batch_size)
library(manifestoR)
library(dplyr)
library(stringr)
library(quanteda)
library(ggplot2)
library(quanteda.textplots)
library(stringr)
library(reticulate)
library(tibble)
library(purrr)
batch_size <- 16L  # CPU 建议 8~32 之间试；越大越快但越吃内存
sent_res <- py$climate_sentiment(as.list(qs_df$qs_text), batch_size = batch_size)
comm_res <- py$climate_commitment(as.list(qs_df$qs_text), batch_size = batch_size)
qs_df <- qs_df %>%
mutate(
cb_sent_label = tolower(unlist(sent_res$label)),
cb_sent_score = as.numeric(unlist(sent_res$score)),
cb_comm_label = tolower(unlist(comm_res$label)),
cb_comm_score = as.numeric(unlist(comm_res$score))
)
qs_df <- qs_df %>%
mutate(
cb_sent_label = tolower(unlist(sent_res$label)),
cb_sent_score = as.numeric(unlist(sent_res$score)),
cb_comm_label = tolower(unlist(comm_res$label)),
cb_comm_score = as.numeric(unlist(comm_res$score))
)
qs_df <- qs_df %>%
mutate(
cb_sent_label = tolower(unlist(sent_res$label)),
cb_sent_score = as.numeric(unlist(sent_res$score)),
cb_comm_label = tolower(unlist(comm_res$label)),
cb_comm_score = as.numeric(unlist(comm_res$score))
)
View(qs_df)
print("ClimateBERT sentiment labels:")
print(py$sent_id2label())
print(table(qs_df$cb_sent_label, useNA = "ifany"))
print("ClimateBERT commitment labels:")
print(py$comm_id2label())
print(table(qs_df$cb_comm_label, useNA = "ifany"))
qs_df <- qs_df %>%
mutate(
cb_is_commit = stringr::str_detect(cb_comm_label, "commit") &
!stringr::str_detect(cb_comm_label, "no|not|non")
)
# 4a) 等权（每条准句算 1）
party_year_cb_equal <- qs_df %>%
group_by(partyabbrev, partyname, year) %>%
summarise(
cb_risk_share = mean(cb_sent_label == "risk", na.rm = TRUE),
cb_opp_share  = mean(cb_sent_label == "opportunity", na.rm = TRUE),
cb_neu_share  = mean(cb_sent_label == "neutral", na.rm = TRUE),
cb_commit_share = mean(cb_is_commit, na.rm = TRUE),
n_qs = dplyr::n(),
.groups = "drop"
)
View(qs_df)
View(uk_qs)
View(qs_df)
View(qs_df)
View(uk_qs)
View(qs_df)
DETE_LOCAL <- "D:/hf_models/climatebert_detector"
CLIM_DETE_MODEL <- if (dir.exists(DETE_LOCAL)) normalizePath(DETE_LOCAL) else "climatebert/distilroberta-base-climate-detector"
## 用 python 端加载两个 pipeline，并定义可从 R 调用的批量预测函数
py_run_string(sprintf("
from transformers import pipeline
import math
SENT_MODEL = r'''%s'''
COMM_MODEL = r'''%s'''
DETE_MODEL = r'''%s'''
sent_pipe = pipeline('text-classification', model=SENT_MODEL, truncation=True, max_length=256)
comm_pipe = pipeline('text-classification', model=COMM_MODEL, truncation=True, max_length=256)
dete_pipe = pipeline('text-classification', model=DETE_MODEL, truncation=True, max_length=256)
def _run_pipe(pipe, texts, batch_size=16):
bs = int(batch_size)   # ✅关键：防止 R 传 float 导致 range() 报错
texts = list(texts)
labels, scores = [], []
for i in range(0, len(texts), bs):
batch = texts[i:i+bs]
preds = pipe(batch, batch_size=bs, truncation=True)
for p in preds:
# 有些 pipeline 会返回 list[list[dict]]，这里兜底
if isinstance(p, list):
p = p[0]
labels.append(p.get('label'))
scores.append(float(p.get('score', math.nan)))
return {'label': labels, 'score': scores}
def climate_detect(texts, batch_size=16):
return _run_pipe(dete_pipe, list(texts), batch_size)
def climate_sentiment(texts, batch_size=16):
return _run_pipe(sent_pipe, list(texts), batch_size)
def climate_commitment(texts, batch_size=16):
return _run_pipe(comm_pipe, list(texts), batch_size)
def det_id2label():
return dict(dete_pipe.model.config.id2label)
def sent_id2label():
return dict(sent_pipe.model.config.id2label)
def comm_id2label():
return dict(comm_pipe.model.config.id2label)
", CLIM_SENT_MODEL, CLIM_COMM_MODEL, CLIM_DETE_MODEL))
batch_size <- 16L  # ✅用整数L，避免传到 python 变 float
det_res <- py$climate_detect(as.list(qs_df$qs_text), batch_size = batch_size)
qs_df <- qs_df %>%
mutate(
det_label = tolower(unlist(det_res$label)),
det_score = as.numeric(unlist(det_res$score))
)
# 只对 detector 判定为 yes（且置信度够） 的句子跑后续模型
qs_yes_idx <- which(qs_df$det_label == "yes" & qs_df$det_score >= 0.5)
sent_lab <- rep(NA_character_, nrow(qs_df)); sent_sco <- rep(NA_real_, nrow(qs_df))
comm_lab <- rep(NA_character_, nrow(qs_df)); comm_sco <- rep(NA_real_, nrow(qs_df))
sent_res <- py$climate_sentiment(as.list(qs_df$qs_text[qs_yes_idx]), batch_size = batch_size)
comm_res <- py$climate_commitment(as.list(qs_df$qs_text[qs_yes_idx]), batch_size = batch_size)
sent_lab[qs_yes_idx] <- tolower(unlist(sent_res$label))
sent_sco[qs_yes_idx] <- as.numeric(unlist(sent_res$score))
comm_lab[qs_yes_idx] <- tolower(unlist(comm_res$label))
comm_sco[qs_yes_idx] <- as.numeric(unlist(comm_res$score))
qs_df <- qs_df %>%
mutate(
cb_sent_label = sent_lab,
cb_sent_score = sent_sco,
cb_comm_label = comm_lab,
cb_comm_score = comm_sco
)
# 看看 label 到底长啥样（应该是这些）
print(py$det_id2label())   # no/yes
print(py$sent_id2label())  # opportunity/neutral/risk
print(py$comm_id2label())  # no/yes
View(qs_df)
View(qs_df)
# 4a) 等权（每条准句算 1）
party_year_cb_equal <- qs_df %>%
group_by(partyabbrev, partyname, year) %>%
summarise(
cb_risk_share = mean(cb_sent_label == "risk", na.rm = TRUE),
cb_opp_share  = mean(cb_sent_label == "opportunity", na.rm = TRUE),
cb_neu_share  = mean(cb_sent_label == "neutral", na.rm = TRUE),
cb_commit_share = mean(cb_is_commit, na.rm = TRUE),
n_qs = dplyr::n(),
.groups = "drop"
)
View(qs_df)
View(qs_df)
View(uk_qs)
View(qs_df)
View(qs_df)
party_year_cb_w <- qs_df %>%
group_by(party, year) %>%
summarise(
cb_risk_share = weighted.mean(cb_sent_label == "risk", w = qs_nwords, na.rm = TRUE),
cb_opp_share  = weighted.mean(cb_sent_label == "opportunity", w = qs_nwords, na.rm = TRUE),
cb_neu_share  = weighted.mean(cb_sent_label == "neutral", w = qs_nwords, na.rm = TRUE),
cb_commit_share = weighted.mean(cb_is_commit, w = qs_nwords, na.rm = TRUE),
n_qs = dplyr::n(),
.groups = "drop"
)
View(party_year_cb_w)
# 4b) 按句子长度加权（更稳一点） + 额外输出 detector 的 climate_share + 权重
party_year_cb_w <- qs_df %>%
mutate(
det_is_climate = (det_label == "yes" & det_score >= 0.5)
) %>%
group_by(party, year) %>%
summarise(
# detector: 气候相关句子占比（按句长加权）
climate_share = weighted.mean(det_is_climate, w = qs_nwords, na.rm = TRUE),
# sentiment shares（只在 climate=yes 的句子上有 label；非气候为 NA，会被 na.rm 去掉）
cb_risk_share = weighted.mean(cb_sent_label == "risk",        w = qs_nwords, na.rm = TRUE),
cb_opp_share  = weighted.mean(cb_sent_label == "opportunity", w = qs_nwords, na.rm = TRUE),
cb_neu_share  = weighted.mean(cb_sent_label == "neutral",     w = qs_nwords, na.rm = TRUE),
# commitment share（同理，非气候为 NA）
cb_commit_share = weighted.mean(cb_is_commit, w = qs_nwords, na.rm = TRUE),
# 权重信息（做 year-level 汇总时用）
qs_words = sum(qs_nwords, na.rm = TRUE),
n_qs     = dplyr::n(),
.groups = "drop"
)
View(party_year_cb_w)
View(qs_df)
qs_df <- qs_df %>%
mutate(
cb_is_commit = stringr::str_detect(cb_comm_label, "yes") &
!stringr::str_detect(cb_comm_label, "no|not|non")
)
# 4b) 按句子长度加权（更稳一点） + 额外输出 detector 的 climate_share + 权重
party_year_cb_w <- qs_df %>%
mutate(
det_is_climate = (det_label == "yes" & det_score >= 0.5)
) %>%
group_by(party, year) %>%
summarise(
# detector: 气候相关句子占比（按句长加权）
climate_share = weighted.mean(det_is_climate, w = qs_nwords, na.rm = TRUE),
# sentiment shares（只在 climate=yes 的句子上有 label；非气候为 NA，会被 na.rm 去掉）
cb_risk_share = weighted.mean(cb_sent_label == "risk",        w = qs_nwords, na.rm = TRUE),
cb_opp_share  = weighted.mean(cb_sent_label == "opportunity", w = qs_nwords, na.rm = TRUE),
cb_neu_share  = weighted.mean(cb_sent_label == "neutral",     w = qs_nwords, na.rm = TRUE),
# commitment share（同理，非气候为 NA）
cb_commit_share = weighted.mean(cb_is_commit, w = qs_nwords, na.rm = TRUE),
# 权重信息（做 year-level 汇总时用）
qs_words = sum(qs_nwords, na.rm = TRUE),
n_qs     = dplyr::n(),
.groups = "drop"
)
View(party_year_cb_w)
party_year_all <- party_year %>%
left_join(party_year_cb_w, by = c("party", "year"))
View(party_year)
View(party_year)
View(party_election)
View(party_year)
View(party_election)
View(party_mean)
View(party_year_cb_w)
View(party_mean)
View(party_election)
View(party_year_cb_w)
View(party_year)
View(party_year_cb_w)
View(qs_df)
View(doc_level)
qs_df2 <- qs_df %>%
mutate(
is_climate = det_label == "yes" & det_score >= 0.5,
w = qs_nwords
)
# 先把 commitment 转二元（你已有逻辑也行）
qs_df2 <- qs_df2 %>%
mutate(cb_is_commit = cb_comm_label == "yes")  # 注意：commitment 模型通常就是 yes/no，别用 detect("commit") 了
bert_manifesto <- qs_df2 %>%
group_by(manifesto_id) %>%
summarise(
# “气候句占比”（你可以理解为 detector-based attention）
cb_climate_share = weighted.mean(is_climate, w = w, na.rm = TRUE),
# 在 climate==yes 的句子中，risk/opportunity/neutral 的份额（句长加权）
cb_risk_share = weighted.mean(cb_sent_label == "risk", w = w, na.rm = TRUE),
cb_opp_share  = weighted.mean(cb_sent_label == "opportunity", w = w, na.rm = TRUE),
cb_neu_share  = weighted.mean(cb_sent_label == "neutral", w = w, na.rm = TRUE),
# commitment 份额（同样在 climate==yes 的句子里更合理）
cb_commit_share = weighted.mean(cb_is_commit, w = w, na.rm = TRUE),
n_qs = n(),
.groups = "drop"
)
View(bert_manifesto)
doc_level_all <- doc_level %>%
left_join(bert_manifesto, by = "manifesto_id")
View(doc_level_all)
party_year_all <- doc_level_all %>%
group_by(partyabbrev, partyname, year) %>%
summarise(
attention_window = sum(green_tokens, na.rm = TRUE) / sum(all_tokens, na.rm = TRUE),
cb_climate_share = mean(cb_climate_share, na.rm = TRUE),
cb_risk_share    = mean(cb_risk_share, na.rm = TRUE),
cb_opp_share     = mean(cb_opp_share, na.rm = TRUE),
cb_commit_share  = mean(cb_commit_share, na.rm = TRUE),
.groups = "drop"
)
View(party_year_cb_w)
View(party_year_all)
View(party_year_all)
View(party_year)
View(party_year_cb_w)
View(frame_counts)
View(mpds)
View(mpds_uk_rile)
View(mpds_uk_rile)
View(party_year_all)
View(party_year_cb_w)
View(party_year_all)
party_year_all <- doc_level_all %>%
group_by(partyabbrev, partyname,party, year) %>%
summarise(
attention_window = sum(green_tokens, na.rm = TRUE) / sum(all_tokens, na.rm = TRUE),
cb_climate_share = mean(cb_climate_share, na.rm = TRUE),
cb_risk_share    = mean(cb_risk_share, na.rm = TRUE),
cb_opp_share     = mean(cb_opp_share, na.rm = TRUE),
cb_commit_share  = mean(cb_commit_share, na.rm = TRUE),
.groups = "drop"
)
View(party_year_all)
View(party_year_all)
party_year_all <- party_year_all %>%
left_join(mpds_uk_rile, by = c("party", "year"))
View(party_year_all)
View(party_year_all)
cb_lr_year <- party_year_all %>%
filter(!is.na(year), !is.na(rile)) %>%
mutate(lr = ifelse(rile < 0, "Left", "Right")) %>%
group_by(year, lr) %>%
summarise(
cb_climate_share = mean(cb_climate_share, na.rm = TRUE),
cb_commit_share  = mean(cb_commit_share,  na.rm = TRUE),
cb_risk_share    = mean(cb_risk_share,    na.rm = TRUE),
cb_opp_share     = mean(cb_opp_share,     na.rm = TRUE),
n_party_year     = n(),
.groups = "drop"
)
ggplot(cb_lr_year, aes(x = year, y = cb_climate_share, color = lr)) +
geom_line(linewidth = 1) +
geom_point(size = 2) +
labs(
x = "Year",
y = "Climate share (ClimateBERT detector)",
color = "Ideology (RILE)",
title = "ClimateBERT: Climate salience over time (Left vs Right)"
) +
theme_minimal()
ggplot(cb_lr_year, aes(x = year, y = cb_commit_share, color = lr)) +
geom_line(linewidth = 1) +
geom_point(size = 2) +
labs(
x = "Year",
y = "Commitment share (ClimateBERT)",
color = "Ideology (RILE)",
title = "ClimateBERT: Commitment over time (Left vs Right)"
) +
theme_minimal()
View(doc_level_all)
party_year_all <- doc_level_all %>%
group_by(partyabbrev, partyname,party, year) %>%
summarise(
attention_window = sum(green_tokens, na.rm = TRUE) / sum(all_tokens, na.rm = TRUE),
cb_climate_share = mean(cb_climate_share, na.rm = TRUE),
cb_risk_share    = mean(cb_risk_share, na.rm = TRUE),
cb_opp_share     = mean(cb_opp_share, na.rm = TRUE),
cb_commit_share  = mean(cb_commit_share, na.rm = TRUE),
cb_neu_share  = mean(cb_neu_share, na.rm = TRUE)
.groups = "drop"
View(doc_level_all)
party_year_all <- doc_level_all %>%
group_by(partyabbrev, partyname,party, year) %>%
summarise(
attention_window = sum(green_tokens, na.rm = TRUE) / sum(all_tokens, na.rm = TRUE),
cb_climate_share = mean(cb_climate_share, na.rm = TRUE),
cb_risk_share    = mean(cb_risk_share, na.rm = TRUE),
cb_opp_share     = mean(cb_opp_share, na.rm = TRUE),
cb_commit_share  = mean(cb_commit_share, na.rm = TRUE),
cb_neu_share  = mean(cb_neu_share, na.rm = TRUE),
.groups = "drop"
)
party_year_all <- party_year_all %>%
left_join(mpds_uk_rile, by = c("party", "year"))
View(party_year_all)
View(party_year_all)
trend_all <- party_year_all %>%
group_by(year) %>%
summarise(
risk = mean(cb_risk_share, na.rm = TRUE),
neutral = mean(cb_neu_share, na.rm = TRUE),
opportunity = mean(cb_opp_share, na.rm = TRUE),
n = dplyr::n(),
.groups = "drop"
) %>%
pivot_longer(cols = c(risk, neutral, opportunity),
names_to = "stance", values_to = "share")
install.packages("tidyr")
library(tidyr)
trend_all <- party_year_all %>%
group_by(year) %>%
summarise(
risk = mean(cb_risk_share, na.rm = TRUE),
neutral = mean(cb_neu_share, na.rm = TRUE),
opportunity = mean(cb_opp_share, na.rm = TRUE),
n = dplyr::n(),
.groups = "drop"
) %>%
pivot_longer(cols = c(risk, neutral, opportunity),
names_to = "stance", values_to = "share")
ggplot(trend_all, aes(x = year, y = share, color = stance)) +
geom_line(linewidth = 1) +
geom_point(size = 2) +
labs(
x = "Year",
y = "Share within climate sentences (ClimateBERT)",
color = "Stance",
title = "ClimateBERT framing over time (risk / neutral / opportunity)"
) +
theme_minimal()
View(party_year_all)
## ==========================================================
## Scatter: risk / neutral / opportunity over time (all party-years)
## Add this AFTER party_year_all is created
## ==========================================================
# 1) 先把 wide 变 long（不依赖 tidyr）
tmp <- party_year_all[, c("partyabbrev", "year", "cb_risk_share", "cb_neu_share", "cb_opp_share")]
stance_long <- data.frame(
partyabbrev = rep(tmp$partyabbrev, times = 3),
year        = rep(tmp$year,        times = 3),
stance      = rep(c("risk", "neutral", "opportunity"), each = nrow(tmp)),
share       = c(tmp$cb_risk_share, tmp$cb_neu_share, tmp$cb_opp_share)
)
# 去掉 NA（比如早年 detector=0 导致 risk/opp/neu 都是 NA）
stance_long <- stance_long[!is.na(stance_long$share), ]
# 2) 一张图三类 stance 的散点（颜色区分 stance）
library(ggplot2)
ggplot(stance_long, aes(x = year, y = share, color = stance)) +
geom_point(alpha = 0.35, size = 1.8, position = position_jitter(width = 0.15, height = 0)) +
labs(
x = "Year",
y = "Share (ClimateBERT stance within detected climate sentences)",
title = "ClimateBERT stance over time (all party-year observations)",
color = "Stance"
) +
theme_minimal()
# 3)（可选）如果你觉得三条混在一起太乱：分面成三张小面板
ggplot(stance_long, aes(x = year, y = share)) +
geom_point(alpha = 0.4, size = 1.6, position = position_jitter(width = 0.15, height = 0)) +
facet_wrap(~ stance, ncol = 1) +
labs(
x = "Year",
y = "Share",
title = "ClimateBERT stance over time (all party-year observations)"
) +
theme_minimal()
View(uk_qs)

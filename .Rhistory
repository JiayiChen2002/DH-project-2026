summarise(text = paste(text, collapse = " "), .groups = "drop") %>%
mutate(
year = as.integer(substr(as.character(date), 1, 4))
)
### 加入党名
mpds <- mp_maindataset()
uk_party_labels <- mpds %>%
filter(countryname == "United Kingdom") %>%
select(party, date, partyname, partyabbrev) %>%
distinct()
uk_doc <- uk_doc %>%
left_join(uk_party_labels, by = c("party", "date"))
##建语料库--分析
corp <- corpus(uk_doc, text_field = "text")
docvars(corp, "party") <- uk_doc$party
docvars(corp, "partyabbrev") <- uk_doc$partyabbrev
docvars(corp, "partyname") <- uk_doc$partyname
docvars(corp, "year") <- uk_doc$year
toks <- tokens(
corp,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = FALSE
) %>%
tokens_tolower()
# 复合短语：把 "climate change" 变成单 token：climate_change
toks <- tokens_compound(
toks,
pattern = phrase(c("climate change", "net zero", "energy transition", "green transition")),
concatenator = "_"
)
##绿色窗口的设立
target_terms <- c(
"climate_change",
"net_zero",
"emissions",
"carbon",
"renewable*",
"green",
"energy_transition",
"green_transition"
)
# 4.1 设窗口大小（你可以改成 20）
W <- 10
toks_green <- tokens_select(
toks,
pattern = target_terms,
selection = "keep",
window = W,
padding = TRUE   # 保持窗口位置（便于理解“窗口”）
)
# 去掉 padding 产生的空 token（不同版本可能表现略不同，稳妥起见做一次清理）
toks_green <- tokens_remove(toks_green, pattern = "", valuetype = "fixed")
##Attention proxy
att_df <- data.frame(
manifesto_id = docnames(toks),
all_tokens   = ntoken(toks),
green_tokens = ntoken(toks_green)
) %>%
mutate(attention = green_tokens / all_tokens)
##LSD
# 6.1 把绿色窗口变成 dfm
dfm_green <- dfm(toks_green)
# 6.2 LSD 词典 lookup
dict_lsd <- data_dictionary_LSD2015
dfm_lsd <- dfm_lookup(dfm_green, dictionary = dict_lsd)
# 6.3 提取计数（转成 data.frame）
lsd_counts <- convert(dfm_lsd, to = "data.frame")
# 6.4 组装 pos/neg（按上面的合并逻辑）
sent_df <- lsd_counts %>%
transmute(
manifesto_id = doc_id,
pos = positive + neg_negative,
neg = negative + neg_positive
) %>%
mutate(
net_sent = ifelse((pos + neg) == 0, NA, (pos - neg) / (pos + neg)),
pos_neg_ratio = ifelse(neg == 0, NA, pos / neg)
)
#Framing
dict_frame <- dictionary(list(
opportunity = c("job*", "innov*", "invest*", "growth", "industry*", "technology*", "productiv*"),
cost        = c("cost*", "bill*", "tax*", "burden*", "price*", "expens*")
))
dfm_frame <- dfm_lookup(dfm_green, dictionary = dict_frame)
frame_counts <- convert(dfm_frame, to = "data.frame") %>%
transmute(
manifesto_id = doc_id,
opp = opportunity,
cost = cost
) %>%
mutate(
frame_total = opp + cost,
opp_share = ifelse(frame_total == 0, NA, opp / frame_total),
cost_share = ifelse(frame_total == 0, NA, cost / frame_total)
)
##合并所有指标
doc_level <- uk_doc %>%
select(manifesto_id, party, partyabbrev, partyname, year) %>%
left_join(att_df,  by = "manifesto_id") %>%
left_join(sent_df, by = "manifesto_id") %>%
left_join(frame_counts, by = "manifesto_id")
party_year <- doc_level %>%
group_by(partyabbrev, partyname, year) %>%
summarise(
# attention：平均（也可以用 sum(green_tokens)/sum(all_tokens)）
attention = sum(green_tokens, na.rm = TRUE) / sum(all_tokens, na.rm = TRUE),
pos = sum(pos, na.rm = TRUE),
neg = sum(neg, na.rm = TRUE),
net_sent = ifelse((pos + neg) == 0, NA, (pos - neg) / (pos + neg)),
opp = sum(opp, na.rm = TRUE),
cost = sum(cost, na.rm = TRUE),
opp_share = ifelse((opp + cost) == 0, NA, opp / (opp + cost)),
cost_share = ifelse((opp + cost) == 0, NA, cost / (opp + cost)),
.groups = "drop"
)
##画图
#1.Net sentiment over time
ggplot(party_year, aes(x = year, y = net_sent, color = partyabbrev)) +
geom_line() +
geom_point(size = 1) +
labs(x = "Year", y = "Net sentiment (LSD)", color = "Party") +
theme_minimal()
#2. Attention over time
ggplot(party_year, aes(x = year, y = attention, color = partyabbrev)) +
geom_line() +
geom_point(size = 1) +
labs(x = "Year", y = "Attention (green window tokens / all tokens)", color = "Party") +
theme_minimal()
View(dfm_frame)
View(toks_green)
# 以 climate_change 为例
kw <- kwic(toks, pattern = "climate_change", window = 10)
# 看前 20 条（课堂展示通常够用了）
head(kw, 20)
View(lsd_counts)
View(lsd_counts)
View(sent_df)
View(sent_df)
View(doc_level)
View(sent_df)
View(doc_level)
View(uk_doc)
View(dict_frame)
View(att_df)
View(dict_lsd)
View(dict_frame)
View(dfm_lsd)
View(dfm_green)
View(att_df)
View(uk_qs)
View(lsd_counts)
View(frame_counts)
View(att_df)
##建语料库--分析
uk_doc <- uk_doc %>% mutate(manifesto_id = as.character(manifesto_id))
corp <- corpus(uk_doc, text_field = "text", docid_field = "manifesto_id")
docvars(corp, "party") <- uk_doc$party
docvars(corp, "partyabbrev") <- uk_doc$partyabbrev
docvars(corp, "partyname") <- uk_doc$partyname
docvars(corp, "year") <- uk_doc$year
toks <- tokens(
corp,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = FALSE
) %>%
tokens_tolower()
# 复合短语：把 "climate change" 变成单 token：climate_change
toks <- tokens_compound(
toks,
pattern = phrase(c("climate change", "net zero", "energy transition", "green transition")),
concatenator = "_"
)
##绿色窗口的设立
target_terms <- c(
"climate_change",
"net_zero",
"emissions",
"carbon",
"renewable*",
"green",
"energy_transition",
"green_transition"
)
# 4.1 设窗口大小（你可以改成 20）
W <- 10
toks_green <- tokens_select(
toks,
pattern = target_terms,
selection = "keep",
window = W,
padding = TRUE   # 保持窗口位置（便于理解“窗口”）
)
# 去掉 padding 产生的空 token（不同版本可能表现略不同，稳妥起见做一次清理）
toks_green <- tokens_remove(toks_green, pattern = "", valuetype = "fixed")
##Attention proxy
att_df <- data.frame(
manifesto_id = docnames(toks),
all_tokens   = ntoken(toks),
green_tokens = ntoken(toks_green)
) %>%
mutate(attention = green_tokens / all_tokens)
##LSD
# 6.1 把绿色窗口变成 dfm
dfm_green <- dfm(toks_green)
# 6.2 LSD 词典 lookup
dict_lsd <- data_dictionary_LSD2015
dfm_lsd <- dfm_lookup(dfm_green, dictionary = dict_lsd)
# 6.3 提取计数（转成 data.frame）
lsd_counts <- convert(dfm_lsd, to = "data.frame")
# 6.4 组装 pos/neg（按上面的合并逻辑）
sent_df <- lsd_counts %>%
transmute(
manifesto_id = doc_id,
pos = positive + neg_negative,
neg = negative + neg_positive
) %>%
mutate(
net_sent = ifelse((pos + neg) == 0, NA, (pos - neg) / (pos + neg)),
pos_neg_ratio = ifelse(neg == 0, NA, pos / neg)
)
#Framing
dict_frame <- dictionary(list(
opportunity = c("job*", "innov*", "invest*", "growth", "industry*", "technology*", "productiv*"),
cost        = c("cost*", "bill*", "tax*", "burden*", "price*", "expens*")
))
dfm_frame <- dfm_lookup(dfm_green, dictionary = dict_frame)
frame_counts <- convert(dfm_frame, to = "data.frame") %>%
transmute(
manifesto_id = doc_id,
opp = opportunity,
cost = cost
) %>%
mutate(
frame_total = opp + cost,
opp_share = ifelse(frame_total == 0, NA, opp / frame_total),
cost_share = ifelse(frame_total == 0, NA, cost / frame_total)
)
##合并所有指标
doc_level <- uk_doc %>%
select(manifesto_id, party, partyabbrev, partyname, year) %>%
left_join(att_df,  by = "manifesto_id") %>%
left_join(sent_df, by = "manifesto_id") %>%
left_join(frame_counts, by = "manifesto_id")
party_year <- doc_level %>%
group_by(partyabbrev, partyname, year) %>%
summarise(
# attention：平均（也可以用 sum(green_tokens)/sum(all_tokens)）
attention = sum(green_tokens, na.rm = TRUE) / sum(all_tokens, na.rm = TRUE),
pos = sum(pos, na.rm = TRUE),
neg = sum(neg, na.rm = TRUE),
net_sent = ifelse((pos + neg) == 0, NA, (pos - neg) / (pos + neg)),
opp = sum(opp, na.rm = TRUE),
cost = sum(cost, na.rm = TRUE),
opp_share = ifelse((opp + cost) == 0, NA, opp / (opp + cost)),
cost_share = ifelse((opp + cost) == 0, NA, cost / (opp + cost)),
.groups = "drop"
)
##画图
#1.Net sentiment over time
ggplot(party_year, aes(x = year, y = net_sent, color = partyabbrev)) +
geom_line() +
geom_point(size = 1) +
labs(x = "Year", y = "Net sentiment (LSD)", color = "Party") +
theme_minimal()
#2. Attention over time
ggplot(party_year, aes(x = year, y = attention, color = partyabbrev)) +
geom_line() +
geom_point(size = 1) +
labs(x = "Year", y = "Attention (green window tokens / all tokens)", color = "Party") +
theme_minimal()
# 以 climate_change 为例
kw <- kwic(toks, pattern = "climate_change", window = 10)
# 看前 20 条（课堂展示通常够用了）
head(kw, 20)
View(uk_party_labels)
View(lsd_counts)
View(uk_party_labels)
View(doc_level)
View(uk_doc)
View(dict_frame)
View(uk_doc)
uk_doc <- uk_doc %>%
mutate(
partyabbrev = ifelse(is.na(partyabbrev) | partyabbrev == "",
partyname,   # 或者用 partyname
partyabbrev)
)
uk_doc <- uk_doc %>%
mutate(
partyabbrev = ifelse(is.na(partyabbrev) | partyabbrev == "",
partyname,   # 或者用 partyname
partyabbrev)
)
# 0.2 加载
library(manifestoR)
library(dplyr)
library(stringr)
library(quanteda)
library(ggplot2)
uk_doc <- uk_doc %>%
mutate(
partyabbrev = ifelse(is.na(partyabbrev) | partyabbrev == "",
partyname,   # 或者用 partyname
partyabbrev)
)
View(uk_doc)
View(uk_doc)
#1.Net sentiment over time
ggplot(party_year, aes(x = year, y = net_sent, color = partyabbrev)) +
geom_line() +
geom_point(size = 1) +
labs(x = "Year", y = "Net sentiment (LSD)", color = "Party") +
theme_minimal()
##建语料库--分析
uk_doc <- uk_doc %>% mutate(manifesto_id = as.character(manifesto_id))
corp <- corpus(uk_doc, text_field = "text", docid_field = "manifesto_id")
docvars(corp, "party") <- uk_doc$party
docvars(corp, "partyabbrev") <- uk_doc$partyabbrev
docvars(corp, "partyname") <- uk_doc$partyname
docvars(corp, "year") <- uk_doc$year
toks <- tokens(
corp,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = FALSE
) %>%
tokens_tolower()
# 复合短语：把 "climate change" 变成单 token：climate_change
toks <- tokens_compound(
toks,
pattern = phrase(c("climate change", "net zero", "energy transition", "green transition")),
concatenator = "_"
)
##绿色窗口的设立
target_terms <- c(
"climate_change",
"net_zero",
"emissions",
"carbon",
"renewable*",
"green",
"energy_transition",
"green_transition"
)
# 4.1 设窗口大小（你可以改成 20）
W <- 10
toks_green <- tokens_select(
toks,
pattern = target_terms,
selection = "keep",
window = W,
padding = TRUE   # 保持窗口位置（便于理解“窗口”）
)
# 去掉 padding 产生的空 token（不同版本可能表现略不同，稳妥起见做一次清理）
toks_green <- tokens_remove(toks_green, pattern = "", valuetype = "fixed")
##Attention proxy
att_df <- data.frame(
manifesto_id = docnames(toks),
all_tokens   = ntoken(toks),
green_tokens = ntoken(toks_green)
) %>%
mutate(attention = green_tokens / all_tokens)
##LSD
# 6.1 把绿色窗口变成 dfm
dfm_green <- dfm(toks_green)
# 6.2 LSD 词典 lookup
dict_lsd <- data_dictionary_LSD2015
dfm_lsd <- dfm_lookup(dfm_green, dictionary = dict_lsd)
# 6.3 提取计数（转成 data.frame）
lsd_counts <- convert(dfm_lsd, to = "data.frame")
# 6.4 组装 pos/neg（按上面的合并逻辑）
sent_df <- lsd_counts %>%
transmute(
manifesto_id = doc_id,
pos = positive + neg_negative,
neg = negative + neg_positive
) %>%
mutate(
net_sent = ifelse((pos + neg) == 0, NA, (pos - neg) / (pos + neg)),
pos_neg_ratio = ifelse(neg == 0, NA, pos / neg)
)
#Framing
dict_frame <- dictionary(list(
opportunity = c("job*", "innov*", "invest*", "growth", "industry*", "technology*", "productiv*"),
cost        = c("cost*", "bill*", "tax*", "burden*", "price*", "expens*")
))
dfm_frame <- dfm_lookup(dfm_green, dictionary = dict_frame)
frame_counts <- convert(dfm_frame, to = "data.frame") %>%
transmute(
manifesto_id = doc_id,
opp = opportunity,
cost = cost
) %>%
mutate(
frame_total = opp + cost,
opp_share = ifelse(frame_total == 0, NA, opp / frame_total),
cost_share = ifelse(frame_total == 0, NA, cost / frame_total)
)
##合并所有指标
doc_level <- uk_doc %>%
select(manifesto_id, party, partyabbrev, partyname, year) %>%
left_join(att_df,  by = "manifesto_id") %>%
left_join(sent_df, by = "manifesto_id") %>%
left_join(frame_counts, by = "manifesto_id")
party_year <- doc_level %>%
group_by(partyabbrev, partyname, year) %>%
summarise(
# attention：平均（也可以用 sum(green_tokens)/sum(all_tokens)）
attention = sum(green_tokens, na.rm = TRUE) / sum(all_tokens, na.rm = TRUE),
pos = sum(pos, na.rm = TRUE),
neg = sum(neg, na.rm = TRUE),
net_sent = ifelse((pos + neg) == 0, NA, (pos - neg) / (pos + neg)),
opp = sum(opp, na.rm = TRUE),
cost = sum(cost, na.rm = TRUE),
opp_share = ifelse((opp + cost) == 0, NA, opp / (opp + cost)),
cost_share = ifelse((opp + cost) == 0, NA, cost / (opp + cost)),
.groups = "drop"
)
#1.Net sentiment over time
ggplot(party_year, aes(x = year, y = net_sent, color = partyabbrev)) +
geom_line() +
geom_point(size = 1) +
labs(x = "Year", y = "Net sentiment (LSD)", color = "Party") +
theme_minimal()
ggplot(party_year, aes(x = year, y = attention, color = partyabbrev)) +
geom_line() +
geom_point(size = 1) +
labs(x = "Year", y = "Attention (green window tokens / all tokens)", color = "Party") +
theme_minimal()
install.packages("usethis")
git clone <https://github.com/JiayiChen2002/DH-project.git>
git clone https://github.com/JiayiChen2002/DH-project.git
library(usethis)
install.packages("usethis")
library(usethis)
install.packages(c("reticulate", "tibble", "purrr"))
library(reticulate) library(tibble) library(purrr)
library(reticulate)
install.packages(c("reticulate", "tibble", "purrr"))
library(reticulate)
install.packages(c("reticulate", "tibble", "purrr"))
install.packages(c("reticulate", "tibble", "purrr"))
Sys.which("make")
Sys.which("gcc")
Sys.which("g++")
install.packages(c("reticulate", "tibble", "purrr"))
options(repos = c(CRAN = "https://cloud.r-project.org"))
options(timeout = 600)
install.packages("tibble")
install.packages("reticulate")
install.packages("purrr")
library(purrr)
library(tibble)
install.packages("reticulate")
library(tibble)
library(purrr)
options(repos = c(CRAN = "https://cloud.r-project.org"))
options(timeout = 600)
install.packages("reticulate", dependencies = TRUE)
options(download.file.method = "wininet")
install.packages("reticulate", dependencies = TRUE)
options(download.file.method = "libcurl")
install.packages("reticulate", dependencies = TRUE)
options(repos = c(CRAN = "https://cloud.r-project.org"))
options(timeout = 600)
install.packages("reticulate", dependencies = FALSE)
options(download.file.method = "wininet")
install.packages("reticulate", dependencies = TRUE)
options(repos = c(CRAN = "https://cran.rstudio.com"))
install.packages("reticulate", dependencies = TRUE)
options(repos = c(CRAN = "https://cloud.r-project.org"))
options(download.file.method = "wininet")
options(timeout = 600)
download.packages("reticulate", destdir = tempdir(), type = "win.binary")
install.packages("reticulate")
install.packages("reticulate")
install.packages("C:\Users\cjylj\Downloads\reticulate-main\reticulate-main",
install.packages("C:/Users/cjylj/Downloads/reticulate-main/reticulate-main",
repos = NULL,
type = "source")
install.packages(c('RcppTOML', 'here', 'png'))
install.packages(c('RcppTOML', 'here', 'png'))
install.packages(c('RcppTOML', 'here', 'png'))
install.packages("reticulate")
install.packages("reticulate")
library(reticulate)
library(tibble)
library(purrr)
use_python("/usr/local/bin/python")
reticulate::install_miniconda()          # 只需一次
reticulate::install_miniconda()          # 只需一次
reticulate::install_miniconda()          # 只需一次
reticulate::install_miniconda()          # 只需一次
reticulate::install_miniconda()          # 只需一次
library(reticulate)
library(tibble)
library(purrr)
reticulate::install_miniconda()          # 只需一次
Sys.which("python")
Sys.which("python3")
reticulate::py_config()
library(reticulate)
use_python("D://Python//python.exe", required = TRUE)
py_config()
reticulate::py_install(c("pip", "setuptools", "wheel"), pip = TRUE)
reticulate::py_install(c("numpy", "pandas"), pip = TRUE)
# HF 需要的包
reticulate::py_install(c("transformers", "torch", "sentencepiece"), pip = TRUE)
# 可选：加速/兼容
reticulate::py_install(c("numpy"), pip = TRUE)
